{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.layers import Dense, ReLU, Embedding, BatchNormalization, Concatenate, Conv1D, GlobalMaxPooling1D, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "df_train = pd.read_csv('emotion_data/train.txt',sep=';', names=['sentence', 'label'])\n",
    "df_test = pd.read_csv('emotion_data/test.txt',sep=';', names=['sentence', 'label'])\n",
    "df_val = pd.read_csv('emotion_data/val.txt',sep=';', names=['sentence', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据根据文本内容进行均分,对多标签数据进行欠采样\n",
    "def dataframe_processing(df):\n",
    "    # 数据均等划分\n",
    "    df = df[~df['label'].isin(['love','surprise'])]\n",
    "    min_count = df.value_counts('label').min()\n",
    "    df_banlanced = pd.DataFrame()\n",
    "    labels = df['label'].value_counts().index\n",
    "    \n",
    "    for label in labels:\n",
    "        df_sampled = df[df['label'] == label].sample(n=min_count, random_state=42)\n",
    "        df_banlanced = pd.concat([df_banlanced, df_sampled])\n",
    "    \n",
    "    # XY划分\n",
    "    X_df_banlanced = df_banlanced['sentence']\n",
    "    y_df_banlanced =  df_banlanced['label']\n",
    "    \n",
    "    return X_df_banlanced, y_df_banlanced\n",
    "\n",
    "X_train, y_train= dataframe_processing(df_train)\n",
    "X_test, y_test = dataframe_processing(df_test)\n",
    "X_val, y_val = dataframe_processing(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对多标签进行编码\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "y_val_encoded = encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对文字进行分词处理\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq = pad_sequences(sequences, maxlen=50)\n",
    "y_train_cat = to_categorical(y_train_encoded)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq = pad_sequences(sequences, maxlen=50)\n",
    "y_test_cat = to_categorical(y_test_encoded)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_seq = pad_sequences(sequences, maxlen=50)\n",
    "y_val_cat = to_categorical(y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " embedding_input (InputLaye  [(None, 50)]                 0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " embedding_1_input (InputLa  [(None, 50)]                 0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 50, 32)               320000    ['embedding_input[0][0]']     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 50, 32)               320000    ['embedding_1_input[0][0]']   \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 50, 64)               6208      ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 50, 64)               6208      ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 50, 64)               256       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 50, 64)               256       ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 50, 64)               0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 50, 64)               0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 50, 64)               0         ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 50, 64)               0         ['re_lu_1[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 64)                   0         ['dropout[0][0]']             \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 64)                   0         ['dropout_1[0][0]']           \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128)                  0         ['global_max_pooling1d[0][0]',\n",
      "                                                                     'global_max_pooling1d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  16512     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    516       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 669956 (2.56 MB)\n",
      "Trainable params: 669700 (2.55 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "max_words = 10000\n",
    "max_len = 50\n",
    "embedding_dim = 32\n",
    "\n",
    "# Branch 1\n",
    "branch1 = Sequential()\n",
    "# 嵌入层\n",
    "branch1.add(Embedding(input_dim = max_words, output_dim = embedding_dim, input_length = max_len))\n",
    "# 卷积层\n",
    "branch1.add(Conv1D(64, 3, padding='same', activation='relu'))\n",
    "# 批归一化层\n",
    "branch1.add(BatchNormalization())\n",
    "# ReLU激活函数\n",
    "branch1.add(ReLU())\n",
    "# Dropout 防止过拟合\n",
    "branch1.add(Dropout(0.5))\n",
    "# 全局池化层\n",
    "branch1.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Branch 2\n",
    "branch2 = Sequential()\n",
    "branch2.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "branch2.add(Conv1D(64, 3, padding='same', activation='relu'))\n",
    "branch2.add(BatchNormalization())\n",
    "branch2.add(ReLU())\n",
    "branch2.add(Dropout(0.5))\n",
    "branch2.add(GlobalMaxPooling1D())\n",
    "\n",
    "concatenated = Concatenate()([branch1.output, branch2.output])\n",
    "\n",
    "hid_layer = Dense(128, activation='relu')(concatenated)\n",
    "dropout = Dropout(0.3)(hid_layer)\n",
    "output_layer = Dense(4, activation='softmax')(dropout)\n",
    "\n",
    "model = Model(inputs=[branch1.input, branch2.input], outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 1.6470 - accuracy: 0.2692 - precision: 0.2802 - recall: 0.1080 - val_loss: 1.3854 - val_accuracy: 0.2712 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.3944 - accuracy: 0.3131 - precision: 0.3733 - recall: 0.0390 - val_loss: 1.3849 - val_accuracy: 0.3031 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.3315 - accuracy: 0.3653 - precision: 0.5352 - recall: 0.0294 - val_loss: 1.3836 - val_accuracy: 0.3302 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 1.2846 - accuracy: 0.4010 - precision: 0.6469 - recall: 0.0534 - val_loss: 1.3810 - val_accuracy: 0.3950 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 1.2217 - accuracy: 0.4561 - precision: 0.6829 - recall: 0.1137 - val_loss: 1.3754 - val_accuracy: 0.4469 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 1.1385 - accuracy: 0.5125 - precision: 0.7154 - recall: 0.1976 - val_loss: 1.3649 - val_accuracy: 0.5460 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.0161 - accuracy: 0.5871 - precision: 0.7604 - recall: 0.3240 - val_loss: 1.3448 - val_accuracy: 0.6073 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.8861 - accuracy: 0.6569 - precision: 0.7919 - recall: 0.4608 - val_loss: 1.3153 - val_accuracy: 0.7146 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.7350 - accuracy: 0.7229 - precision: 0.8221 - recall: 0.5803 - val_loss: 1.2684 - val_accuracy: 0.7547 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.6067 - accuracy: 0.7825 - precision: 0.8521 - recall: 0.6893 - val_loss: 1.2087 - val_accuracy: 0.7889 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.4735 - accuracy: 0.8338 - precision: 0.8857 - recall: 0.7708 - val_loss: 1.1310 - val_accuracy: 0.8243 - val_precision: 1.0000 - val_recall: 0.0024\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3905 - accuracy: 0.8669 - precision: 0.9019 - recall: 0.8282 - val_loss: 1.0496 - val_accuracy: 0.8502 - val_precision: 1.0000 - val_recall: 0.0389\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3076 - accuracy: 0.8983 - precision: 0.9205 - recall: 0.8722 - val_loss: 0.9531 - val_accuracy: 0.8644 - val_precision: 1.0000 - val_recall: 0.1203\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2798 - accuracy: 0.9085 - precision: 0.9279 - recall: 0.8867 - val_loss: 0.8623 - val_accuracy: 0.8809 - val_precision: 0.9917 - val_recall: 0.2807\n",
      "Epoch 15/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2296 - accuracy: 0.9268 - precision: 0.9415 - recall: 0.9116 - val_loss: 0.7650 - val_accuracy: 0.8892 - val_precision: 0.9900 - val_recall: 0.4682\n",
      "Epoch 16/25\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1952 - accuracy: 0.9395 - precision: 0.9521 - recall: 0.9251 - val_loss: 0.6668 - val_accuracy: 0.8998 - val_precision: 0.9886 - val_recall: 0.6156\n",
      "Epoch 17/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1685 - accuracy: 0.9489 - precision: 0.9593 - recall: 0.9390 - val_loss: 0.5728 - val_accuracy: 0.9021 - val_precision: 0.9786 - val_recall: 0.7017\n",
      "Epoch 18/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1534 - accuracy: 0.9551 - precision: 0.9622 - recall: 0.9453 - val_loss: 0.5002 - val_accuracy: 0.9021 - val_precision: 0.9698 - val_recall: 0.7571\n",
      "Epoch 19/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1443 - accuracy: 0.9569 - precision: 0.9620 - recall: 0.9488 - val_loss: 0.4345 - val_accuracy: 0.9127 - val_precision: 0.9704 - val_recall: 0.8113\n",
      "Epoch 20/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1244 - accuracy: 0.9637 - precision: 0.9676 - recall: 0.9573 - val_loss: 0.3828 - val_accuracy: 0.9116 - val_precision: 0.9607 - val_recall: 0.8361\n",
      "Epoch 21/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1094 - accuracy: 0.9681 - precision: 0.9718 - recall: 0.9622 - val_loss: 0.3395 - val_accuracy: 0.9092 - val_precision: 0.9526 - val_recall: 0.8538\n",
      "Epoch 22/25\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0933 - accuracy: 0.9712 - precision: 0.9727 - recall: 0.9672 - val_loss: 0.3063 - val_accuracy: 0.9080 - val_precision: 0.9494 - val_recall: 0.8620\n",
      "Epoch 23/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0958 - accuracy: 0.9711 - precision: 0.9740 - recall: 0.9666 - val_loss: 0.2826 - val_accuracy: 0.9139 - val_precision: 0.9413 - val_recall: 0.8703\n",
      "Epoch 24/25\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0846 - accuracy: 0.9732 - precision: 0.9762 - recall: 0.9695 - val_loss: 0.2584 - val_accuracy: 0.9139 - val_precision: 0.9408 - val_recall: 0.8809\n",
      "Epoch 25/25\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0744 - accuracy: 0.9792 - precision: 0.9812 - recall: 0.9768 - val_loss: 0.2399 - val_accuracy: 0.9186 - val_precision: 0.9383 - val_recall: 0.8974\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "batch_size = 256\n",
    "epochs = 25\n",
    "history = model.fit([X_train_seq, X_train_seq], y_train_cat, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=([X_val_seq, X_val_seq], y_val_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9464 - precision: 0.9596 - recall: 0.9286\n",
      "Loss: 0.2, Accuracy: 0.95, Precision: 0.96, Recall: 0.93\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy, percision, recall) = model.evaluate([X_test_seq, X_test_seq], y_test_cat)\n",
    "print(f'Loss: {round(loss, 2)}, Accuracy: {round(accuracy, 2)}, Precision: {round(percision, 2)}, Recall: {round(recall, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'sadness', 'sadness', 'joy', 'sadness', 'fear', 'anger',\n",
       "       'joy', 'joy', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试一下数据\n",
    "test_data = df_test['sentence'].head(10)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_len)\n",
    "predictions = model.predict([test_data,test_data])\n",
    "\n",
    "predicted_label = [np.argmax(prediction) for prediction in predictions]\n",
    "    \n",
    "\n",
    "encoder.inverse_transform(predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
