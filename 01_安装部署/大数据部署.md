# 资源规划
| 主机名 | IP             | 配置     | 操作系统                      | 角色          |
| ------ | -------------- | -------- | ----------------------------- | ------------- |
| hdp01  | 192.168.30.100 | 2 核/64G | CentOS Linux release 7.9.2009 |           |
| hdp02  | 192.168.30.101 | 2 核/32G | CentOS Linux release 7.9.2009 |           |
| hdp03  | 192.168.30.102 | 2 核/32G | CentOS Linux release 7.9.2009 |          |
| hdp04  | 192.168.30.103 | 2 核/32G | CentOS Linux release 7.9.2009 |          |
| hdp05  | 192.168.30.104 | 2 核/32G | CentOS Linux release 7.9.2009 |          |
| hdp06  | 192.168.30.105 | 2 核/32G | CentOS Linux release 7.9.2009 |          |
| hdp07  | 192.168.30.106 | 2 核/32G | CentOS Linux release 7.9.2009 |          |
| hdp08  | 192.168.30.107 | 2 核/32G | CentOS Linux release 7.9.2009 |          |

# 基本框架
**存储**：HA HDFS + Hive

**计算**：Spark

**调度**：Dolphinschedual

**分布式协调**：Zookeeper

# 环境配置
##  关闭防火墙
**查看防火状态**
```shell
systemctl status firewalld # 防火墙状态

systemctl stop firewalld.service  # 停止firewalld服务
systemctl disable firewalld.service # 开机禁用firewalld服务
```
**重启防火墙**
```shell
systemctl enable firewalld
service iptables restart
```
## jdk8 安装

```bash
yum list java*

yum install java-1.8.0-openjdk-devel.x86_64

# 安装位置(与现有java环境不一致，要修改环境变量JAVA_HOME)
cd /usr/lib/jvm/
```
## 修改环境变量
```shell
vi ~/bashrc
```
```shell
# 添加
export SOFTWARE_HOME=/home/software
export JAVA_HOME=/usr/jdk1.8.0_161
export JRE_HOME=/opt/app/jdk1.8.0_161/jre
export HADOOP_HOME=$SOFTWARE_HOME/hadoop/hadoop-3.3.5
export ZK_HOME=$SOFTWARE_HOME/zookeeper/apache-zookeeper-3.5.10-bin
export SPARK_HOME=$SOFTWARE_HOME/spark/spark-3.5.1-bin-hadoop3
export HIVE_HOME=$SOFTWARE_HOME/hive/apache-hive-3.1.2-bin

export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH
export PATH=$PATH:$JAVA_HOME/bin
```
```shell
# 更新环境变量
source ~/bashrc
```
## 配置免密登录
**生成密码对**
```shell
ssh-keygen -t rsa
```
**发送密码对到其他服务器**
```shell
ssh-copy-id root@hdp01
```
## 修改 yum 源
主要是为了加快 **yum**下载速度
```powershell
# 备份
cp -a /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak
# 下载
wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo
# 清除缓存
yum clean all
# 刷新缓存
yum makecache
```

## 安装相关依赖
```shell
yum install gcc gcc-c++ make autoconf automake libtool curl lzo-devel zlib-devel openssl openssl-devel ncurses-devel snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop libXtst zlib -y

yum install -y doxygen cyrus-sasl* saslwrapper-devel*
```

## 上传文件并解压
```shell
# 创建安装目录
mkdir -p /home/software/hadoop /home/software/hive /home/software/zookeeper /home/software/spark /home/software/docker
```

```shell
# 上传并解压
cd /home/software/hadoop
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.3.5/hadoop-3.3.5.tar.gz
tar -zxvf hadoop-3.3.5.tar.gz
```

## 集群时间同步
```shell
ntpdate ntp5.aliyun.com
# 如果是内网环境，就找一台做时间服务器
```

# Zookeeper 安装
## 前置条件
- jdk8+

## 下载上传
```shell
# 下载
cd /home/software/zookeeper
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.5.10/apache-zookeeper-3.5.10-bin.tar.gz

# 解压
tar -zxvf apache-zookeeper-3.5.10-bin.tar.gz
```
## 更改配置
- zoo.cfg

# Hadoop 安装
高可用模式
## 前置条件
- zookeeper 集群

## 配置文件
配置文件路径 `$HADOOP_HOME/etc/hadoop`
- hadoop-env.sh
- core-site.xml
- hdfs-site.xml
- mapred-site.xml
- yarn-site.xml
- workers

# Hive 安装
## 前置条件
- jdk8+
- 安装 mysql 
- mysql jdbc驱动
```shell
# 下载到hive lib
cd /home/software/hive/apache-hive-3.1.2-bin/lib

wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.32/mysql-connector-java-5.1.32.jar
```

## 下载上传解压
```shell
mkdir -p /home/software/hive && cd /home/software/hive # hive安装包
wget https://archive.apache.org/dist/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz
tar -zxvf apache-hive-3.1.2-bin.tar.gz
```

## 解决 Hive 与 Hadoop 之间 guava 版本差异
```shell
rm -rf /home/software/hive/apache-hive-3.1.2-bin/lib/guava-19.0.jar
cp $HADOOP_HOME/share/hadoop/common/lib/guava-27.0-jre.jar /home/software/hive/apache-hive-3.1.2-bin/lib/
```

## 配置文件
- hive-env.sh
- hive-site.xml

## 初始化元数据
```shell
cd /home/software/hive/apache-hive-3.1.2-bin
  
bin/schematool -initSchema -dbType mysql -verbos
#初始化成功会在mysql中创建74张表
```

## 创建 Hive 存储目录
```shell
hadoop fs -mkdir /tmp
hadoop fs -mkdir -p /warehouse
hadoop fs -chmod g+w /tmp
hadoop fs -chmod g+w /warehouse
```

## 解决 Hive 注释乱码问题
连接 Hive 对应 mysql

```sql
use hive;
alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8;
alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;
```
# Spark 集群
## 前置条件
- jdk8+
- python3.8+
- zookeeper 集群

## 下载上传
```shell
mkdir -p /home/software/spark && cd /home/software/spark
wget https://www.apache.org/dyn/closer.lua/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz
```

## 配置
- spark-env.sh
- workers

# Dolphinschedual 集群
## 前置条件
- ssh免密登录
- jdk8+
- mysql
- mysql jdbc(8.0.16)驱动
```shell
下载地址：https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar

# 下载到
  - api-server/libs 
  - alert-server/libs 
  - master-server/libs 
  - worker-server/libs 
  - tools/libs
  - standalone-server/libs/standalone-server
```

## 下载上传
```shell
mkdir -p /home/software/dolphinscheduler && cd /home/software/dolphinscheduler
wget https://www.apache.org/dyn/closer.lua/dolphinscheduler/3.2.1/apache-dolphinscheduler-3.2.1-src.tar.gz
```

## 修改配置
配置文件路径 `/home/software/dolphinscheduler/apache-dolphinscheduler-3.2.1-bin/bin`
- install.sh

## 数据库初始化
```shell
mysql -uroot -pHan2Te0Win-19
```
```sql
CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
GRANT ALL PRIVILEGES ON dolphinscheduler.* TO 'root'@'%' IDENTIFIED BY 'Han2Te0Win-19';
GRANT ALL PRIVILEGES ON dolphinscheduler.* TO 'root'@'localhost' IDENTIFIED BY 'Han2Te0Win-19';
flush privileges;
```
**环境配置**
```shell
vi ~/.bashrc
```
```shell
# 尾部添加
export DATABASE=mysql
export SPRING_PROFILES_ACTIVE=${DATABASE}
export SPRING_DATASOURCE_URL="jdbc:mysql://192.168.30.101:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8&useSSL=false"
export SPRING_DATASOURCE_USERNAME='root'
export SPRING_DATASOURCE_PASSWORD='Han2Te0Win-19'
```
```shell
source ~/.bashrc
```

**数据库初始化**
```shell
tools/bin/upgrade-schema.sh
```

## 更新文件夹权限
```shell
chmod -R 755 apache-dolphinscheduler-3.2.1-bin/
```

## 初始化
```shell
./install.sh
```

# Superset
在`192.168.30.149`使用docker安装，

# openmetadata